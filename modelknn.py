# -*- coding: utf-8 -*-
"""ModelKNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1m9gfxnB-Qkokb66oLIC611qnrsKlObhY
"""

# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np

from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from imblearn.under_sampling import RandomUnderSampler

import joblib


# 1. LOAD DATA
df = pd.read_csv("Lifestyle_and_Health_Risk_Prediction_Synthetic_Dataset.csv")

# 2. OUTLIER HANDLING (IQR CLIPPING)
df_clean = df.copy()
numeric_cols = df_clean.select_dtypes(include=["float64", "int64"]).columns

for col in numeric_cols:
    Q1 = df_clean[col].quantile(0.25)
    Q3 = df_clean[col].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    df_clean[col] = np.clip(df_clean[col], lower, upper)

# 3. LABEL ENCODING
cols_to_encode = [
    'married', 'exercise', 'sugar_intake',
    'alcohol', 'smoking', 'profession',
    'health_risk'
]

encoders = {}
for col in cols_to_encode:
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col])
    encoders[col] = le

# 4. FEATURE SELECTION & SPLIT
X = df_clean[['age', 'bmi', 'smoking', 'alcohol', 'sleep', 'sugar_intake']]
y = df_clean['health_risk']

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.30,
    stratify=y,
    random_state=42
)

# 5. UNDERSAMPLING (TRAINING SET ONLY)
undersampler = RandomUnderSampler(random_state=42)
X_train_res, y_train_res = undersampler.fit_resample(X_train, y_train)

print("Distribusi kelas setelah undersampling:")
print(y_train_res.value_counts())

# 6. SCALING (WAJIB UNTUK KNN)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_res)
X_test_scaled = scaler.transform(X_test)

# 7. KNN – GRID SEARCH OPTIMIZATION
knn_model = KNeighborsClassifier()

param_grid_knn = {
    'n_neighbors': range(1, 31, 2),   # k ganjil
    'metric': ['euclidean', 'manhattan', 'minkowski']
}

grid_search_knn = GridSearchCV(
    estimator=knn_model,
    param_grid=param_grid_knn,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid_search_knn.fit(X_train_scaled, y_train_res)

best_knn_model = grid_search_knn.best_estimator_

print("\nBest Parameter KNN:")
print(grid_search_knn.best_params_)

# 8. SAVE MODEL & PREPROCESSOR
joblib.dump(best_knn_model, "knn_best_model.sav")
joblib.dump(scaler, "scaler.sav")
joblib.dump(encoders, "encoders.sav")


# 9. EVALUATION – KNN
y_pred_knn = best_knn_model.predict(X_test_scaled)

knn_acc = accuracy_score(y_test, y_pred_knn)

print("\nAkurasi KNN Terbaik:", knn_acc)
print("\nClassification Report (KNN):")
print(classification_report(y_test, y_pred_knn))
print(confusion_matrix(y_test, y_pred_knn))